# -*- coding: utf-8 -*-
"""Specailized_AI_Model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s8XkaBwXoGEAJIUFC0SsaHKUdWeos_52
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
import numpy as np
from google.colab import files
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, r2_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Conv1D, MaxPooling1D, Flatten
df = pd.read_csv("cleaned_stock_prices.csv")
def clean_volume(v):
    if isinstance(v, str):
        v = v.replace(",", "").strip()
        if v.endswith("M"):
            return float(v[:-1]) * 1_000_000
        if v.endswith("K"):
            return float(v[:-1]) * 1_000
        if v == "-" or v == "":
            return 0
    try:
        return float(v)
    except:
        return 0
if "Vol." in df.columns:
    df["Vol."] = df["Vol."].apply(clean_volume)
def clean_percent(p):
    if isinstance(p, str):
        p = p.replace("%", "")
        if p.strip() == "":
            return 0
        return float(p) / 100
    try:
        return float(p)
    except:
        return 0
if "Change %" in df.columns:
    df["Change %"] = df["Change %"].apply(clean_percent)
if "Date" in df.columns:
    df = df.drop(columns=["Date"])
df = df.select_dtypes(include=[np.number])
print("Columns after cleaning:", df.columns.tolist())
target = "Price" if "Price" in df.columns else df.columns[-1]
print("Using target:", target)
scaler = MinMaxScaler()
scaled = scaler.fit_transform(df)
WINDOW = 30
X, y = [], []
for i in range(len(scaled) - WINDOW):
    X.append(scaled[i:i+WINDOW])
    y.append(scaled[i+WINDOW][df.columns.get_loc(target)])
X = np.array(X)
y = np.array(y)
train_size = int(0.8 * len(X))
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]
lstm = Sequential([
    LSTM(64, input_shape=(WINDOW, X.shape[2])),
    Dense(32, activation='relu'),
    Dense(1)
])
lstm.compile(optimizer='adam', loss='mse')
print("\nTraining LSTM...")
lstm.fit(X_train, y_train, epochs=15, batch_size=32, verbose=1)
pred_lstm = lstm.predict(X_test)
mse_lstm = mean_squared_error(y_test, pred_lstm)
r2_lstm = r2_score(y_test, pred_lstm)
cnn = Sequential([
    Conv1D(32, 3, activation='relu', input_shape=(WINDOW, X.shape[2])),
    MaxPooling1D(2),
    Flatten(),
    Dense(32, activation='relu'),
    Dense(1)
])
cnn.compile(optimizer='adam', loss='mse')
print("\nTraining 1D-CNN...")
cnn.fit(X_train, y_train, epochs=15, batch_size=32, verbose=1)
pred_cnn = cnn.predict(X_test)
mse_cnn = mean_squared_error(y_test, pred_cnn)
r2_cnn = r2_score(y_test, pred_cnn)
print("\n================= MODEL RESULTS =================")
print(f"LSTM → MSE: {mse_lstm:.6f},  R2: {r2_lstm:.6f}")
print(f"CNN  → MSE: {mse_cnn:.6f},  R2: {r2_cnn:.6f}")
print("\nDone!")

import zipfile

with zipfile.ZipFile("time_series_outputs.zip", "w") as zipf:
    results.to_csv("time_series_model_results.csv", index=False)
    zipf.write("time_series_model_results.csv")

    lstm.save("lstm_model.h5")
    zipf.write("lstm_model.h5")

    cnn.save("cnn_model.h5")
    zipf.write("cnn_model.h5")

files.download("time_series_outputs.zip")